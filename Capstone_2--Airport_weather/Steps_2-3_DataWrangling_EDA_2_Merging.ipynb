{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weather events\n",
      "Loading flight data\n"
     ]
    }
   ],
   "source": [
    "#Load the weather data and merge them into our two DataFrames.'''\n",
    "path = r'D:\\Springboard_DataSci\\Assignments\\Capstone_2--Airport_weather\\data'\n",
    "os.chdir(path)\n",
    "print('Loading weather events')\n",
    "weather_events = pd.read_csv('weather_events.csv')\n",
    "print('Loading flight data')\n",
    "departing_flights = pd.read_csv('departing_flights.csv')\n",
    "arriving_flights = pd.read_csv('arriving_flights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames.\n",
    "departure_events = departing_flights.merge(\n",
    "    weather_events, how='left', left_on=['ORIGIN','DepartureDate'],\n",
    "    right_on=['Airport','Date'], validate='one_to_many')\n",
    "arrival_events = arriving_flights.merge(\n",
    "    weather_events, how='left', left_on=['DEST','ArrivalDate'],\n",
    "    right_on=['Airport','Date'], validate='one_to_many')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant columns.\n",
    "departure_events.drop(['Airport','Date'], axis=1, inplace=True)\n",
    "arrival_events.drop(['Airport','Date'], axis=1, inplace=True)\n",
    "\n",
    "# Clean up the column names.\n",
    "inputVars = pd.Series(['Cold','Fog','Hail','Rain','Snow','Storm'], name='Code')\n",
    "column_renames = {'ARR_DEL15':'ArrivDel',\n",
    "                  'DEP_DEL15':'DepartDel',\n",
    "                  'ColdCode':'Cold',\n",
    "                  'FogCode':'Fog',\n",
    "                  'HailCode':'Hail',\n",
    "                  'RainCode':'Rain',\n",
    "                  'SnowCode':'Snow',\n",
    "                  'StormCode':'Storm'}\n",
    "departure_events.rename(columns=column_renames, inplace=True)\n",
    "arrival_events.rename(columns=column_renames, inplace=True)\n",
    "\n",
    "# NaN's mean no weather events on that day. Fill them in with 0's.\n",
    "for column in inputVars:\n",
    "    departure_events[column].fillna(0, inplace=True)\n",
    "    arrival_events[column].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Exploratory data analysis'''\n",
    "FRAC_CANCELLED = 'FracCancelled'\n",
    "FRAC_DELAYED = 'FracDelayed'\n",
    "departure_events[FRAC_CANCELLED] = departure_events.WeatherCancelled/departure_events.Flights\n",
    "arrival_events[FRAC_CANCELLED] = arrival_events.WeatherCancelled/arrival_events.Flights\n",
    "departure_events[FRAC_DELAYED] = departure_events.WeatherDelayed/departure_events.Flights\n",
    "arrival_events[FRAC_DELAYED] = arrival_events.WeatherDelayed/arrival_events.Flights\n",
    "\n",
    "X_dep = departure_events.loc[:, inputVars]\n",
    "X_arr = arrival_events.loc[:, inputVars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the correlation matrix of data with X's features as columns.\n",
    "def corrMatrixAndMax(df, labels=inputVars):\n",
    "    corr = df.corr()\n",
    "    n = corr.shape[0]\n",
    "    max_corr_ID = np.argmax(np.abs(corr) - np.eye(n))\n",
    "    return corr, np.unravel_index(max_corr_ID, [n,n])\n",
    "\n",
    "#Get the value, and row and column labels of a particular df coordinate. Rounding is arbitrary.\n",
    "def getCorrNameCoords(df, coordinates):\n",
    "    row = coordinates[0]; col = coordinates[1]\n",
    "    return round(df.iloc[row, col], 3), df.index[row], df.index[col]\n",
    "        \n",
    "#Max absolute difference.\n",
    "maxAbsDiff = lambda A, B, axis=None: np.max(np.abs(A-B), axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviation from X_dep and array of ints: Cold     0.0\n",
      "Fog      0.0\n",
      "Hail     0.0\n",
      "Rain     0.0\n",
      "Snow     0.0\n",
      "Storm    0.0\n",
      "dtype: float64\n",
      "\n",
      "Deviation from X_arr and array of ints: Cold     0.0\n",
      "Fog      0.0\n",
      "Hail     0.0\n",
      "Rain     0.0\n",
      "Snow     0.0\n",
      "Storm    0.0\n",
      "dtype: float64\n",
      "\n",
      "Calculating correlation matrices\n",
      "Max abs difference between Corr_X_dep and Corr_X_arr: Cold     0.000011\n",
      "Fog      0.000403\n",
      "Hail     0.000040\n",
      "Rain     0.000403\n",
      "Snow     0.000040\n",
      "Storm    0.000054\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Deviation from X_dep and array of ints:', maxAbsDiff(X_dep, X_dep.astype(int)) )\n",
    "print('\\nDeviation from X_arr and array of ints:', maxAbsDiff(X_arr, X_arr.astype(int)) )\n",
    "X_dep = X_dep.astype(int)\n",
    "X_arr = X_arr.astype(int)\n",
    "\n",
    "print('\\nCalculating correlation matrices')\n",
    "Corr_X_dep, coords_max_Corr_X_dep = corrMatrixAndMax(X_dep)\n",
    "Corr_X_arr, coords_max_Corr_X_arr = corrMatrixAndMax(X_arr)\n",
    "print('Max abs difference between Corr_X_dep and Corr_X_arr:', maxAbsDiff(Corr_X_dep, Corr_X_arr))\n",
    "#Nearly identical, which makes sense given that they're from the same dates and airports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Departure event correlation matrix:\n",
      "           Cold       Fog      Hail      Rain      Snow     Storm\n",
      "Cold   1.000000  0.008870  0.014899 -0.004855  0.024090  0.022348\n",
      "Fog    0.008870  1.000000  0.017653  0.111326  0.163653  0.029486\n",
      "Hail   0.014899  0.017653  1.000000  0.068580  0.178120  0.016327\n",
      "Rain  -0.004855  0.111326  0.068580  1.000000  0.008625  0.091570\n",
      "Snow   0.024090  0.163653  0.178120  0.008625  1.000000  0.035830\n",
      "Storm  0.022348  0.029486  0.016327  0.091570  0.035830  1.000000\n",
      "Greatest correlation and name and coordinates: (0.178, 'Hail', 'Snow')\n",
      "\n",
      "Arrival event correlation matrix:\n",
      "           Cold       Fog      Hail      Rain      Snow     Storm\n",
      "Cold   1.000000  0.008874  0.014903 -0.004844  0.024100  0.022352\n",
      "Fog    0.008874  1.000000  0.017657  0.111729  0.163612  0.029488\n",
      "Hail   0.014903  0.017657  1.000000  0.068540  0.178129  0.016333\n",
      "Rain  -0.004844  0.111729  0.068540  1.000000  0.008646  0.091516\n",
      "Snow   0.024100  0.163612  0.178129  0.008646  1.000000  0.035847\n",
      "Storm  0.022352  0.029488  0.016333  0.091516  0.035847  1.000000\n",
      "Greatest correlation and name and coordinates: (0.178, 'Hail', 'Snow')\n"
     ]
    }
   ],
   "source": [
    "EV_CORR_MTRX = ' event correlation matrix:\\n'\n",
    "CORR_NAME_COORDS = 'Greatest correlation and name and coordinates:'\n",
    "print('\\nDeparture' + EV_CORR_MTRX + str(Corr_X_dep))\n",
    "print(CORR_NAME_COORDS, getCorrNameCoords(Corr_X_dep, coords_max_Corr_X_dep))\n",
    "print('\\nArrival' + EV_CORR_MTRX + str(Corr_X_arr))\n",
    "print(CORR_NAME_COORDS, getCorrNameCoords(Corr_X_arr, coords_max_Corr_X_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is suspicious. Hail is a warm-weather event; snow is a cold-weather event. \n",
    "Let's look at the Hail and Snow codes to see how much overlap there is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Departures:\n",
      "   Hail  Snow  count\n",
      "0     0     0  22054\n",
      "1     0     1    484\n",
      "2     0     2    173\n",
      "3     0     3     97\n",
      "4     1     0     37\n",
      "5     1     1     10\n",
      "6     1     2     11\n",
      "7     1     3     14\n",
      "\n",
      "Arrivals:\n",
      "   Hail  Snow  count\n",
      "0     0     0  22086\n",
      "1     0     1    484\n",
      "2     0     2    173\n",
      "3     0     3     97\n",
      "4     1     0     37\n",
      "5     1     1     10\n",
      "6     1     2     11\n",
      "7     1     3     14\n"
     ]
    }
   ],
   "source": [
    "def SumByPair(df, label1, label2):\n",
    "    return df.groupby([label1, label2]).size().reset_index().rename(columns={0:'count'})\n",
    "print('\\nDepartures:\\n' + str(SumByPair(X_dep, 'Hail', 'Snow')))\n",
    "print('\\nArrivals:\\n' + str(SumByPair(X_arr, 'Hail', 'Snow')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly half the Hail=1 codes are correlated with Snow>0 codes. This is a problem,\n",
    "and we need to investigate it. Let's take a look at these 35 days in the departure\n",
    "and arrival events DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hailAndSnowDep = departure_events[\n",
    "    (departure_events.Hail==1) & (departure_events.Snow>0)]\n",
    "hailAndSnowArr = arrival_events[\n",
    "    (arrival_events.Hail==1) & (arrival_events.Snow>0)]\n",
    "\n",
    "# The date/airport overlap is probably large. Let's compare these two DFs.\n",
    "hailAndSnowEvents = hailAndSnowDep[['ORIGIN','DepartureDate','Hail','Snow']].merge(\n",
    "    hailAndSnowArr[['DEST','ArrivalDate','Hail','Snow']], how='outer',\n",
    "    left_on=['ORIGIN','DepartureDate'], right_on=['DEST','ArrivalDate'],\n",
    "    suffixes=('_dep','_arr'))\n",
    "\n",
    "clashes = hailAndSnowEvents.apply(\n",
    "    lambda row: any((row['ORIGIN']!=row['DEST'], row['Hail_dep']!=row['Hail_arr'],\n",
    "                     row['DepartureDate']!=row['ArrivalDate'], row['Snow_dep']!=row['Snow_arr'])), axis=1)\n",
    "print('Any clashes between departure/arrival columns?', clashes.any())\n",
    "# None. We can just use hailAndSnowDep or hailAndSnowArr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hailAndSnowDep = hailAndSnowDep[['ORIGIN','DepartureDate','Hail','Snow']]\n",
    "del(hailAndSnowArr, hailAndSnowEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nOverlapping hail and snow days:')\n",
    "print('\\n' + str(hailAndSnowDep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_X_dep = X_dep[(X_dep.T != 0).any()]\n",
    "nonzero_X_arr = X_arr[(X_arr.T != 0).any()]\n",
    "nonzero_Corr_X_dep, nonzero_coords_max_Corr_X_dep = corrMatrixAndMax(nonzero_X_dep)\n",
    "nonzero_Corr_X_arr, nonzero_coords_max_Corr_X_arr = corrMatrixAndMax(nonzero_X_arr)\n",
    "print('Max abs difference between nonzero_Corr_X_dep and nonzero_Corr_X_arr:',\n",
    "      maxAbsDiff(nonzero_Corr_X_dep, nonzero_Corr_X_arr))\n",
    "#Identical correlation matrices, so we don't have to separate arrival/departure here.\n",
    "\n",
    "print('\\nNonzero' + EV_CORR_MTRX, nonzero_Corr_X_dep)\n",
    "print(CORR_NAME_COORDS, getCorrNameCoords(nonzero_Corr_X_dep, nonzero_coords_max_Corr_X_dep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the greatest correlation is between rain and fog, at about -0.297. Paradoxically,\n",
    "this correlation was positive with all zero rows included! Perhaps we have the same\n",
    "effect here as with hail and cold. Let's find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nDepartures:\\n' + str(SumByPair(X_dep, 'Rain', 'Fog')))\n",
    "print('\\nDepartures (fog first):\\n' + str(SumByPair(X_dep, 'Fog', 'Rain')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nNonzero rows:\\n' + str(SumByPair(nonzero_X_dep, 'Rain', 'Fog')))\n",
    "print('\\nNonzero rows (fog first):\\n' + str(SumByPair(nonzero_X_dep, 'Fog', 'Rain')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly all the 0-0 rows got cut. All other rows are preserved. The negative correlation after\n",
    "the cut shows that an overlap between rain and fog is uncommon. Intuitively this makes sense, as\n",
    "fog is generally a fair-weather event and rain is generally a poor-weather event. Incidentally,\n",
    "note that light rain is more likely when the fog is heavy.\n",
    "\n",
    "Because the untrimmed departure and arrival correlation matrices are nearly identical,\n",
    "we will just use the departure events now. Let's see what the average values per\n",
    "column are, weighted by flight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Avg = pd.DataFrame(map(list, zip(inputVars.values, np.average(\n",
    "    X_dep, axis=0, weights=departure_events.Flights))), columns=['Code', 'WtAvg'])\n",
    "Avg = Avg.set_index('Code')['WtAvg']\n",
    "print('\\nWeighted averages: ' + str(Avg) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do some plots, per code, categorized by code value. To make things\n",
    "simpler we will not weight these values for now. There are a ton of outliers; we\n",
    "will do the plots both with and without them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_cancelled = departure_events['FracCancelled']\n",
    "frac_delayed = departure_events['FracDelayed']\n",
    "\n",
    "for showfliers in [True, False]: #Outliers\n",
    "    for weatherCode in inputVars:\n",
    "        unique_codes = np.sort(X_dep[weatherCode].unique()) #makes a Series of value counts indexed by code #\n",
    "        cancelled_per_code = [frac_cancelled[X_dep[weatherCode]==j] for j in unique_codes]\n",
    "        delayed_per_code = [frac_delayed[X_dep[weatherCode]==j] for j in unique_codes]\n",
    "    \n",
    "        fig, axs = plt.subplots(1,2)\n",
    "        axs[0].boxplot(cancelled_per_code, showfliers=showfliers)\n",
    "        axs[0].set_title('Cancellation fraction per code')\n",
    "        axs[1].boxplot(delayed_per_code, showfliers=showfliers)\n",
    "        axs[1].set_title('Delay fraction per code')\n",
    "        for j in [0,1]:\n",
    "            axs[j].set_xticklabels(unique_codes)\n",
    "            axs[j].set_xlabel('Value of \"' + weatherCode + '\"')\n",
    "            axs[j].yaxis.grid(True)\n",
    "        if not showfliers:\n",
    "            plt.savefig('BoxPlot' + weatherCode + '.png')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The medians of some of these features clearly are affected by the feature value;\n",
    "however, none of them seem to add up to much more than about 0.20, meaning that\n",
    "we should not expect that these weather events will have an overwhelming affect\n",
    "on delays and cancellations. Still, there do seem to be trends that emerge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results.\n",
    "departure_events.to_csv('departure_events.csv') #Uncomment to save.\n",
    "arrival_events.to_csv('arrival_events.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
