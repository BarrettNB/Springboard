{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Exploratory data analysis for the weather-airports project.\n",
    "\n",
    "Weather data: https://www.kaggle.com/sobhanmoosavi/us-weather-events\n",
    "Flight delays/cancellations: https://www.transtats.bts.gov/DL_SelectFields.asp\n",
    "Busiest airports: https://www.faa.gov/airports/planning_capacity/passenger_allcargo_stats/passenger/media/preliminary-cy18-commercial-service-enplanements.pdf\n",
    "\n",
    "Created on Fri May 29 14:14:07 2020\n",
    "\n",
    "@author: Barrett\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pytz\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append('D:/Springboard_DataSci/Assignments/Lib')\n",
    "import TimeTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing weather events CSV file\n"
     ]
    }
   ],
   "source": [
    "'''Data collection'''\n",
    "stopwatch = TimeTracker.TimeTracker()\n",
    "# Get all the data.\n",
    "path = r'D:\\Springboard_DataSci\\Assignments\\Capstone_2--Airport_weather\\data'\n",
    "os.chdir(path)\n",
    "print('Importing weather events CSV file')\n",
    "weather_events = pd.read_csv('US_WeatherEvents_2016-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the busiest airports in the US. A source for the 2019 data was not\n",
    "# available at this time, so I assume that the 2018 rankings are the same.\n",
    "# Either way there should not have been a major dropoff in passenger numbers\n",
    "# at the US's busiest airports between 2018 and 2019.'''\n",
    "busiest_US_airports2018 = ['ATL','LAX','ORD','DFW','DEN','JFK','SFO','SEA',\n",
    "                           'LAS','MCO','EWR','CLT','PHX','MIA','IAH','BOS']\n",
    "busiest_US_airports2018 = pd.Series(\n",
    "    busiest_US_airports2018, index=range(1, len(busiest_US_airports2018)+1),\n",
    "    name='Airport')\n",
    "busiest_US_airports2018.index.name = 'Rank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "O'Hare weather events:\n",
      "Rain             1903\n",
      "Snow              566\n",
      "Fog               235\n",
      "Precipitation      44\n",
      "Hail               10\n",
      "Storm               8\n",
      "Cold                3\n",
      "Name: Type, dtype: int64\n",
      "Light       1859\n",
      "Moderate     578\n",
      "Severe       142\n",
      "Heavy        136\n",
      "UNK           44\n",
      "Other         10\n",
      "Name: Severity, dtype: int64\n",
      "Latitude, Longitude: [41.9875] [-87.9319]\n",
      "\n",
      "Newark weather events:\n",
      "Rain             1945\n",
      "Snow              297\n",
      "Fog               114\n",
      "Precipitation      33\n",
      "Hail               17\n",
      "Storm              10\n",
      "Cold                1\n",
      "Name: Type, dtype: int64\n",
      "Light       1648\n",
      "Moderate     504\n",
      "Heavy        131\n",
      "Severe        84\n",
      "UNK           33\n",
      "Other         17\n",
      "Name: Severity, dtype: int64\n",
      "Latitude, Longitude: [40.6827] [-74.1693]\n",
      "\n",
      "Phoenix weather events:\n",
      "Rain             401\n",
      "Fog               23\n",
      "Storm              9\n",
      "Cold               6\n",
      "Precipitation      2\n",
      "Hail               1\n",
      "Name: Type, dtype: int64\n",
      "Light       335\n",
      "Moderate     68\n",
      "Severe       23\n",
      "Heavy        13\n",
      "UNK           2\n",
      "Other         1\n",
      "Name: Severity, dtype: int64\n",
      "['US/Mountain']\n",
      "Latitude, Longitude: [33.4277] [-112.0038]\n"
     ]
    }
   ],
   "source": [
    "'''Explore the weather data.'''\n",
    "# Take a couple airports as a sample\n",
    "weather_ORD = weather_events[weather_events.AirportCode=='KORD']\n",
    "print('\\nO\\'Hare weather events:\\n' + str(weather_ORD.Type.value_counts()))\n",
    "print(weather_ORD.Severity.value_counts())\n",
    "print('Latitude, Longitude:', weather_ORD.LocationLat.unique(), weather_ORD.LocationLng.unique())\n",
    "\n",
    "weather_EWR = weather_events[weather_events.AirportCode=='KEWR']\n",
    "print('\\nNewark weather events:\\n' + str(weather_EWR.Type.value_counts()))\n",
    "print(weather_EWR.Severity.value_counts())\n",
    "print('Latitude, Longitude:', weather_EWR.LocationLat.unique(), weather_EWR.LocationLng.unique())\n",
    "\n",
    "# Need to see what's going on with Phoenix's time zones\n",
    "weather_PHX = weather_events[weather_events.AirportCode=='KPHX']\n",
    "print('\\nPhoenix weather events:\\n' + str(weather_PHX.Type.value_counts()))\n",
    "print(weather_PHX.Severity.value_counts()) #Warmer, drier climate\n",
    "print(weather_PHX.TimeZone.unique()) #Just 'US/Mountain'. PHX is standard time year-round.\n",
    "print('Latitude, Longitude:', weather_PHX.LocationLat.unique(), weather_PHX.LocationLng.unique())\n",
    "weather_events.loc[(weather_events.AirportCode=='KPHX'), 'TimeZone'] = 'US/Arizona'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the airports we need.\n",
    "ICAO_codes = ('K'+busiest_US_airports2018).to_list()\n",
    "weather_events.drop(weather_events.index[np.where(~weather_events.AirportCode.isin(ICAO_codes))[0]], inplace=True)\n",
    "\n",
    "# Recast the 4-lettered ICAO-code index into the 3-lettered IATA codes.\n",
    "weather_events.rename(columns={'AirportCode': 'Airport'}, inplace=True)\n",
    "weather_events.Airport = weather_events.Airport.apply(\n",
    "    lambda prefix: prefix[1:])\n",
    "\n",
    "# Replace the useless index numbers with default indexing.\n",
    "weather_events = weather_events.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['EventId', 'Type', 'Severity', 'StartTime(UTC)', 'EndTime(UTC)',\n",
      "       'TimeZone', 'Airport', 'LocationLat', 'LocationLng', 'City', 'County',\n",
      "       'State', 'ZipCode'],\n",
      "      dtype='object')\n",
      "None \n",
      " Index(['TimeZone', 'Airport', 'LocationLat', 'LocationLng', 'City', 'County',\n",
      "       'State'],\n",
      "      dtype='object')\n",
      "                         City State     TimeZone  LocationLat  LocationLng\n",
      "Airport                                                                   \n",
      "JFK                   Jamaica    NY   US/Eastern      40.6392     -73.7639\n",
      "ORD               Bensenville    IL   US/Central      41.9875     -87.9319\n",
      "BOS               East Boston    MA   US/Eastern      42.3606     -71.0097\n",
      "DEN                    Denver    CO  US/Mountain      39.8466    -104.6562\n",
      "MCO                   Orlando    FL   US/Eastern      28.4183     -81.3241\n",
      "DFW                    Dallas    TX   US/Central      32.8974     -97.0220\n",
      "EWR                    Newark    NJ   US/Eastern      40.6827     -74.1693\n",
      "LAS                 Las Vegas    NV   US/Pacific      36.0719    -115.1634\n",
      "LAX               Los Angeles    CA   US/Pacific      33.9382    -118.3865\n",
      "ATL                   Atlanta    GA   US/Eastern      33.6301     -84.4418\n",
      "SEA                   Seattle    WA   US/Pacific      47.4447    -122.3144\n",
      "SFO             San Francisco    CA   US/Pacific      37.6196    -122.3656\n",
      "CLT      Township 2 Berryhill    NC   US/Eastern      35.2225     -80.9543\n",
      "PHX                   Phoenix    AZ   US/Arizona      33.4277    -112.0038\n",
      "MIA                     Miami    FL   US/Eastern      25.7880     -80.3169\n",
      "IAH                   Houston    TX   US/Central      29.9844     -95.3607\n"
     ]
    }
   ],
   "source": [
    "# Get the details on our airports\n",
    "print(weather_events.columns)\n",
    "unique_airports_weather = weather_events.loc[:, 'TimeZone':'State'].drop_duplicates()\n",
    "print(unique_airports_weather.index.name, '\\n', unique_airports_weather.columns)\n",
    "unique_airports_weather = unique_airports_weather.drop('County', axis=1)\n",
    "unique_airports_weather = unique_airports_weather.set_index('Airport')\n",
    "unique_airports_weather = unique_airports_weather[['City','State','TimeZone','LocationLat','LocationLng']]\n",
    "print(unique_airports_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns: Index(['Type', 'Severity', 'StartTime(UTC)', 'EndTime(UTC)', 'TimeZone',\n",
      "       'Airport'],\n",
      "      dtype='object')\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Latitude and longitudes check out. Let's trim extraneous columns.'''\n",
    "weather_events = weather_events.drop(['EventId','LocationLat','LocationLng',\n",
    "                                      'County','ZipCode','City','State'], axis=1)\n",
    "print('Remaining columns:', weather_events.columns)\n",
    "\n",
    "# '''Get the weather data times into datetime format.'''\n",
    "print(type(weather_events.iloc[0].loc['StartTime(UTC)']))\n",
    "print(type(weather_events.iloc[0].loc['EndTime(UTC)'])) #Both are strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetimes and timezones to the right types of objects.\n",
    "weather_events['StartTime(UTC)'] = pd.to_datetime(weather_events['StartTime(UTC)']).dt.tz_localize('utc')\n",
    "weather_events['EndTime(UTC)'] = pd.to_datetime(weather_events['EndTime(UTC)']).dt.tz_localize('utc')\n",
    "weather_events['TimeZone'] = weather_events['TimeZone'].map(pytz.timezone)\n",
    "\n",
    "# Localize the times to their respective time zones.\n",
    "print('Converting weather times to local time zones')\n",
    "weather_events['StartTimeLocal'] = weather_events.apply(\n",
    "    lambda row: row['StartTime(UTC)'].tz_convert(row['TimeZone']), axis=1)\n",
    "weather_events['EndTimeLocal'] = weather_events.apply(\n",
    "    lambda row: row['EndTime(UTC)'].tz_convert(row['TimeZone']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We no longer need data outside the year 2019. Remove them and reset the index.\n",
    "print('Removing entries completely outside 2019 CE')\n",
    "weather_events = weather_events.drop(weather_events[weather_events.apply(\n",
    "    lambda row: (row['StartTimeLocal'].year>2019) | (row['EndTimeLocal'].year<2019), axis=1)].index)\n",
    "print('Remaining events count:', len(weather_events.index))\n",
    "weather_events = weather_events.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut the columns just down to the ones we need and reorder them.\n",
    "print(weather_events.columns)\n",
    "weather_events = weather_events[['Airport','Type','Severity','StartTimeLocal','EndTimeLocal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many events rolled over from 2018 or to 2020.\n",
    "print('Events that spanned New Year\\'s 2019 or 2020:')\n",
    "events_outside_2019_boolean = weather_events.apply(\n",
    "    lambda row: (row['StartTimeLocal'].year<2019) | (row['EndTimeLocal'].year>2019), axis=1)\n",
    "print(weather_events[events_outside_2019_boolean])\n",
    "# Just 4 out of 7862--0.05%. All four on New Year's Eve 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete some old variables that are no longer needed.\n",
    "del(weather_EWR, weather_ORD, weather_PHX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''Investigate weather types and declare numeric variables for them.'''\n",
    "print(weather_events.Type.value_counts())\n",
    "for weatherType in weather_events.Type.unique():\n",
    "    print('\\nSeverities for weather type ' + weatherType + ':')\n",
    "    print(weather_events[weather_events.Type==weatherType].Severity.value_counts())\n",
    "print('\\nSeverities for all types:\\n', weather_events.Severity.value_counts())\n",
    "'''Rain: Light, Moderate, Heavy\n",
    "Fog: Moderate, Severe\n",
    "Snow: Light, Moderate, Heavy\n",
    "Precipitation: UNK (we need to fix this)\n",
    "Hail: Other\n",
    "Storm: Severe\n",
    "Cold: Severe'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_width = len(weather_events.columns) #get this now before new columns added\n",
    "weather_events['HailCode'] = (weather_events.Type == 'Hail').map(int)\n",
    "weather_events['StormCode'] = (weather_events.Type == 'Storm').map(int)\n",
    "weather_events['ColdCode'] = (weather_events.Type == 'Cold').map(int)\n",
    "\n",
    "LightModerateHeavy = {'Light':1, 'Moderate':2, 'Heavy':3}\n",
    "weather_events['RainCode'] =\\\n",
    "    weather_events[weather_events.Type=='Rain'].Severity.map(LightModerateHeavy)\n",
    "weather_events.RainCode = weather_events.RainCode.fillna(value=0)\n",
    "weather_events['FogCode'] =\\\n",
    "    weather_events[weather_events.Type=='Fog'].Severity.map({'Moderate':1, 'Severe':2})\n",
    "weather_events.FogCode = weather_events.FogCode.fillna(value=0)\n",
    "weather_events['SnowCode'] =\\\n",
    "    weather_events[weather_events.Type=='Snow'].Severity.map(LightModerateHeavy)\n",
    "weather_events.SnowCode = weather_events.SnowCode.fillna(value=0)\n",
    "FIRST_WEATHER_CODE = (weather_events.columns)[DF_width] #needed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix the \"Precipitation\" and \"UNK\" entries.\n",
    "PRECIP = 'Precipitation'; UNK = 'UNK'\n",
    "print('Count of \"' + PRECIP + '\" XOR \"' + UNK + ':\"', len(weather_events\\\n",
    "          [((weather_events.Type == PRECIP) &\n",
    "            (weather_events.Severity != UNK)) |\n",
    "            ((weather_events.Type != PRECIP) &\n",
    "            (weather_events.Severity == UNK))].index)) #Perfect match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nImputing these events')\n",
    "for airport in busiest_US_airports2018:\n",
    "    airport_indeces = weather_events[weather_events.Airport == airport].index\n",
    "    if airport_indeces.size > 0:\n",
    "        assert np.max(np.diff(airport_indeces)) == 1,\\\n",
    "            'Indexes misaligned for ' + str(airport)\n",
    "        weather_current_airport = weather_events.loc[airport_indeces]\n",
    "        unknown_precip_indeces = weather_current_airport\\\n",
    "            [weather_current_airport.Type == PRECIP].index\n",
    "        if len(unknown_precip_indeces)==0:\n",
    "            print(airport, 'has no unknown precipitation')\n",
    "        else:\n",
    "            weather_before_indeces = unknown_precip_indeces-1\n",
    "            weather_after_indeces = unknown_precip_indeces+1\n",
    "            try:\n",
    "                weather_current_airport.loc[weather_before_indeces[0]]\n",
    "            except KeyError:\n",
    "                raise ValueError('First weather event at', airport, 'is unknown precip')\n",
    "            try:\n",
    "                weather_current_airport.loc[weather_after_indeces[-1]]\n",
    "            except KeyError:\n",
    "                raise ValueError('Last weather event at', airport, 'is unknown precip')\n",
    "            # Will need to code a workaround if either of these issues arise.\n",
    "        \n",
    "            # Impute based on averages from entries immediately before and after.\n",
    "            # Round up decimals to nearest integer.\n",
    "            imputation_values = np.ceil((\n",
    "                weather_current_airport.loc[weather_before_indeces, FIRST_WEATHER_CODE:].values\n",
    "                + weather_current_airport.loc[weather_after_indeces, FIRST_WEATHER_CODE:].values)/2).astype(int)\n",
    "            for i, index in enumerate(unknown_precip_indeces):\n",
    "                weather_events.loc[index, FIRST_WEATHER_CODE:] = imputation_values[i]\n",
    "    else:\n",
    "        print(airport, 'has no entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the unneeded columns and some temporary variables.\n",
    "del(index, weather_current_airport, imputation_values, airport_indeces, unknown_precip_indeces,\n",
    "    weather_before_indeces, weather_after_indeces, events_outside_2019_boolean,\n",
    "    PRECIP, UNK, FIRST_WEATHER_CODE, airport, weatherType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather_events.columns)\n",
    "weather_events = weather_events.drop(['Type', 'Severity'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before merging data, analyze the lengths of the weather events.\n",
    "weather_duration = weather_events.apply(\n",
    "    lambda row: (row['EndTimeLocal'] - row['StartTimeLocal']).seconds/3600, axis=1)\n",
    "longestEvent = max(weather_duration)\n",
    "print('Longest weather event: %.1f hours' % longestEvent) # <24 hours. Good.\n",
    "plt.hist(weather_duration, bins=int(longestEvent), color='b', align='left')\n",
    "plt.xlabel('Hours per event')\n",
    "plt.ylabel('Count')\n",
    "plt.show() #Most events are < 2 hours, and almost all are < 8 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize events by date\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    weather_events['StartDate'] = weather_events.apply(lambda row: row['StartTimeLocal'].date(), axis=1)\n",
    "    weather_events['EndDate'] = weather_events.apply(lambda row: row['EndTimeLocal'].date(), axis=1)\n",
    "weather_starts = weather_events.copy()\n",
    "weather_ends = weather_events.copy()\n",
    "weather_starts = weather_starts.drop(['StartTimeLocal','EndTimeLocal','EndDate'], axis=1)\n",
    "weather_ends = weather_ends.drop(['StartTimeLocal','EndTimeLocal','StartDate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a pivot table based on the highest precip code in each column per day.\n",
    "weather_starts = pd.pivot_table(data=weather_starts, index=['Airport','StartDate'], aggfunc=np.max)\n",
    "weather_ends = pd.pivot_table(data=weather_ends, index=['Airport','EndDate'], aggfunc=np.max)\n",
    "\n",
    "# Append weather_starts and weather_ends (the columns are the same).\n",
    "# We no longer need the weather_events DF, so name the result that.\n",
    "weather_events = weather_starts.append(weather_ends).sort_index()\n",
    "\n",
    "# Find the max over each date and rename the index. This is our final result for the weather data.\n",
    "weather_events = pd.pivot_table(data=weather_events, index=['Airport','StartDate'], aggfunc=np.max)\n",
    "weather_events.index.names = ['Airport','Date']\n",
    "print(weather_events.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame and proceed to the flight_data.\n",
    "# weather_events.to_csv('weather_events.csv') #Uncomment to create the file\n",
    "print('Total runtime:', stopwatch.getElapsedTime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
