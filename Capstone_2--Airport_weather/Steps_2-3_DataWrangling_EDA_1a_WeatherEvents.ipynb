{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Exploratory data analysis for the weather-airports project.\n",
    "\n",
    "Part 1a: Weather events\n",
    "\n",
    "Weather data: https://www.kaggle.com/sobhanmoosavi/us-weather-events\n",
    "Flight delays/cancellations: https://www.transtats.bts.gov/DL_SelectFields.asp\n",
    "Busiest airports: https://www.faa.gov/airports/planning_capacity/passenger_allcargo_stats/passenger/media/preliminary-cy18-commercial-service-enplanements.pdf\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pytz\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append('D:/Springboard_DataSci/Assignments/Lib')\n",
    "import TimeTracker\n",
    "\n",
    "START_YEAR = 2016\n",
    "END_YEAR = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing weather events CSV file\n"
     ]
    }
   ],
   "source": [
    "'''Data collection'''\n",
    "stopwatch = TimeTracker.TimeTracker()\n",
    "# Get all the data.\n",
    "path = r'D:\\Springboard_DataSci\\Assignments\\Capstone_2--Airport_weather\\data'\n",
    "os.chdir(path)\n",
    "print('Importing weather events CSV file')\n",
    "weather_events = pd.read_csv('US_WeatherEvents_2016-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any duplicates dropped? False\n"
     ]
    }
   ],
   "source": [
    "# Check for any duplicates.\n",
    "nRows = len(weather_events.index)\n",
    "weather_events.drop_duplicates(inplace=True)\n",
    "print('Any duplicates dropped?', len(weather_events.index)!=nRows) #No duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A source for the 2019 data was not available at this time, so I assume that the 2018\n",
    "busiest airport rankings are the same. Either way there should not have been a major\n",
    "dropoff in passenger numbers at the US's busiest airports between 2018 and 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the busiest airports in the US.\n",
    "busiest_US_airports2018 = ['ATL','LAX','ORD','DFW','DEN','JFK','SFO','SEA',\n",
    "                           'LAS','MCO','EWR','CLT','PHX','MIA','IAH','BOS']\n",
    "busiest_US_airports2018 = pd.Series(\n",
    "    busiest_US_airports2018, index=range(1, len(busiest_US_airports2018)+1),\n",
    "    name='Airport')\n",
    "busiest_US_airports2018.index.name = 'Rank'\n",
    "busiest_US_airports2018.to_csv('busiest_US_airports2018.csv') #For Part 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "O'Hare weather events:\n",
      "Rain             1903\n",
      "Snow              566\n",
      "Fog               235\n",
      "Precipitation      44\n",
      "Hail               10\n",
      "Storm               8\n",
      "Cold                3\n",
      "Name: Type, dtype: int64\n",
      "Light       1859\n",
      "Moderate     578\n",
      "Severe       142\n",
      "Heavy        136\n",
      "UNK           44\n",
      "Other         10\n",
      "Name: Severity, dtype: int64\n",
      "Latitude, Longitude: [41.9875] [-87.9319]\n",
      "\n",
      "Newark weather events:\n",
      "Rain             1945\n",
      "Snow              297\n",
      "Fog               114\n",
      "Precipitation      33\n",
      "Hail               17\n",
      "Storm              10\n",
      "Cold                1\n",
      "Name: Type, dtype: int64\n",
      "Light       1648\n",
      "Moderate     504\n",
      "Heavy        131\n",
      "Severe        84\n",
      "UNK           33\n",
      "Other         17\n",
      "Name: Severity, dtype: int64\n",
      "Latitude, Longitude: [40.6827] [-74.1693]\n",
      "\n",
      "Phoenix weather events:\n",
      "Rain             401\n",
      "Fog               23\n",
      "Storm              9\n",
      "Cold               6\n",
      "Precipitation      2\n",
      "Hail               1\n",
      "Name: Type, dtype: int64\n",
      "Light       335\n",
      "Moderate     68\n",
      "Severe       23\n",
      "Heavy        13\n",
      "UNK           2\n",
      "Other         1\n",
      "Name: Severity, dtype: int64\n",
      "['US/Mountain']\n",
      "Latitude, Longitude: [33.4277] [-112.0038] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Explore the weather data.'''\n",
    "# Take a couple airports as a sample\n",
    "weather_ORD = weather_events[weather_events.AirportCode=='KORD']\n",
    "print('\\nO\\'Hare weather events:\\n' + str(weather_ORD.Type.value_counts()))\n",
    "print(weather_ORD.Severity.value_counts())\n",
    "print('Latitude, Longitude:', weather_ORD.LocationLat.unique(), weather_ORD.LocationLng.unique())\n",
    "\n",
    "weather_EWR = weather_events[weather_events.AirportCode=='KEWR']\n",
    "print('\\nNewark weather events:\\n' + str(weather_EWR.Type.value_counts()))\n",
    "print(weather_EWR.Severity.value_counts())\n",
    "print('Latitude, Longitude:', weather_EWR.LocationLat.unique(), weather_EWR.LocationLng.unique())\n",
    "\n",
    "# Need to see what's going on with Phoenix's time zones\n",
    "weather_PHX = weather_events[weather_events.AirportCode=='KPHX']\n",
    "print('\\nPhoenix weather events:\\n' + str(weather_PHX.Type.value_counts()))\n",
    "print(weather_PHX.Severity.value_counts()) #Warmer, drier climate\n",
    "print(weather_PHX.TimeZone.unique()) #Just 'US/Mountain'. PHX is standard time year-round.\n",
    "print('Latitude, Longitude:', weather_PHX.LocationLat.unique(), weather_PHX.LocationLng.unique(), '\\n')\n",
    "weather_events.loc[(weather_events.AirportCode=='KPHX'), 'TimeZone'] = 'US/Arizona'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the airports we need.\n",
    "ICAO_codes = ('K'+busiest_US_airports2018).to_list()\n",
    "weather_events.drop(weather_events.index[np.where(~weather_events.AirportCode.isin(ICAO_codes))[0]], inplace=True)\n",
    "\n",
    "# Recast the 4-lettered ICAO-code index into the 3-lettered IATA codes.\n",
    "weather_events.rename(columns={'AirportCode': 'Airport'}, inplace=True)\n",
    "weather_events.Airport = weather_events.Airport.apply(\n",
    "    lambda prefix: prefix[1:])\n",
    "\n",
    "# Replace the useless index numbers with default indexing.\n",
    "weather_events = weather_events.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['EventId', 'Type', 'Severity', 'StartTime(UTC)', 'EndTime(UTC)',\n",
      "       'TimeZone', 'Airport', 'LocationLat', 'LocationLng', 'City', 'County',\n",
      "       'State', 'ZipCode'],\n",
      "      dtype='object')\n",
      "None \n",
      " Index(['TimeZone', 'Airport', 'LocationLat', 'LocationLng', 'City', 'County',\n",
      "       'State'],\n",
      "      dtype='object')\n",
      "                         City State     TimeZone  LocationLat  LocationLng\n",
      "Airport                                                                   \n",
      "JFK                   Jamaica    NY   US/Eastern      40.6392     -73.7639\n",
      "ORD               Bensenville    IL   US/Central      41.9875     -87.9319\n",
      "BOS               East Boston    MA   US/Eastern      42.3606     -71.0097\n",
      "DEN                    Denver    CO  US/Mountain      39.8466    -104.6562\n",
      "MCO                   Orlando    FL   US/Eastern      28.4183     -81.3241\n",
      "DFW                    Dallas    TX   US/Central      32.8974     -97.0220\n",
      "EWR                    Newark    NJ   US/Eastern      40.6827     -74.1693\n",
      "LAS                 Las Vegas    NV   US/Pacific      36.0719    -115.1634\n",
      "LAX               Los Angeles    CA   US/Pacific      33.9382    -118.3865\n",
      "ATL                   Atlanta    GA   US/Eastern      33.6301     -84.4418\n",
      "SEA                   Seattle    WA   US/Pacific      47.4447    -122.3144\n",
      "SFO             San Francisco    CA   US/Pacific      37.6196    -122.3656\n",
      "CLT      Township 2 Berryhill    NC   US/Eastern      35.2225     -80.9543\n",
      "PHX                   Phoenix    AZ   US/Arizona      33.4277    -112.0038\n",
      "MIA                     Miami    FL   US/Eastern      25.7880     -80.3169\n",
      "IAH                   Houston    TX   US/Central      29.9844     -95.3607\n"
     ]
    }
   ],
   "source": [
    "# Get the details on our airports\n",
    "print(weather_events.columns)\n",
    "unique_airports_weather = weather_events.loc[:, 'TimeZone':'State'].drop_duplicates()\n",
    "print(unique_airports_weather.index.name, '\\n', unique_airports_weather.columns)\n",
    "unique_airports_weather = unique_airports_weather.drop('County', axis=1)\n",
    "unique_airports_weather = unique_airports_weather.set_index('Airport')\n",
    "unique_airports_weather = unique_airports_weather[['City','State','TimeZone','LocationLat','LocationLng']]\n",
    "print(unique_airports_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns: Index(['Type', 'Severity', 'StartTime(UTC)', 'EndTime(UTC)', 'TimeZone',\n",
      "       'Airport'],\n",
      "      dtype='object')\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Latitude and longitudes check out. Let's trim extraneous columns.'''\n",
    "weather_events = weather_events.drop(['EventId','LocationLat','LocationLng',\n",
    "                                      'County','ZipCode','City','State'], axis=1)\n",
    "print('Remaining columns:', weather_events.columns)\n",
    "\n",
    "# '''Get the weather data times into datetime format.'''\n",
    "print(type(weather_events.iloc[0].loc['StartTime(UTC)']))\n",
    "print(type(weather_events.iloc[0].loc['EndTime(UTC)'])) #Both are strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting weather start times to local time zones\n",
      "Converting weather end times to local time zones\n"
     ]
    }
   ],
   "source": [
    "# Convert datetimes and timezones to the right types of objects.\n",
    "weather_events['StartTime(UTC)'] = pd.to_datetime(weather_events['StartTime(UTC)']).dt.tz_localize('utc')\n",
    "weather_events['EndTime(UTC)'] = pd.to_datetime(weather_events['EndTime(UTC)']).dt.tz_localize('utc')\n",
    "weather_events['TimeZone'] = weather_events['TimeZone'].map(pytz.timezone)\n",
    "\n",
    "# Localize the times to their respective time zones.\n",
    "print('Converting weather start times to local time zones')\n",
    "weather_events['StartTimeLocal'] = weather_events.apply(\n",
    "    lambda row: row['StartTime(UTC)'].tz_convert(row['TimeZone']), axis=1)\n",
    "print('Converting weather end times to local time zones')\n",
    "weather_events['EndTimeLocal'] = weather_events.apply(\n",
    "    lambda row: row['EndTime(UTC)'].tz_convert(row['TimeZone']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing entries completely outside the relevant year(s)\n",
      "Remaining events count: 31126\n"
     ]
    }
   ],
   "source": [
    "# We no longer need data outside the relevant year. Remove them and reset the index.\n",
    "# Irrelevant if all years are selected.\n",
    "print('Removing entries completely outside the relevant year(s)')\n",
    "weather_events = weather_events.drop(weather_events[weather_events.apply(\n",
    "    lambda row: (row['StartTimeLocal'].year > END_YEAR)\\\n",
    "              | (row['EndTimeLocal'].year < START_YEAR), axis=1)].index)\n",
    "print('Remaining events count:', len(weather_events.index))\n",
    "weather_events = weather_events.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Type', 'Severity', 'StartTime(UTC)', 'EndTime(UTC)', 'TimeZone',\n",
      "       'Airport', 'StartTimeLocal', 'EndTimeLocal'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Cut the columns just down to the ones we need and reorder them.\n",
    "print(weather_events.columns)\n",
    "weather_events = weather_events[['Airport','Type','Severity','StartTimeLocal','EndTimeLocal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events that spanned New Year's 2016 or 2020\n",
      "Empty DataFrame\n",
      "Columns: [Airport, Type, Severity, StartTimeLocal, EndTimeLocal]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many events rolled over New Year's at the endpoints.\n",
    "print('Events that spanned New Year\\'s', START_YEAR, 'or', END_YEAR+1)\n",
    "events_outside_our_years = weather_events.apply(\n",
    "    lambda row: (row['StartTimeLocal'].year < START_YEAR)\\\n",
    "        | (row['EndTimeLocal'].year > END_YEAR), axis=1)\n",
    "print(weather_events[events_outside_our_years]) #None!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rain             24127\n",
      "Fog               3811\n",
      "Snow              2306\n",
      "Precipitation      553\n",
      "Storm              172\n",
      "Hail               110\n",
      "Cold                47\n",
      "Name: Type, dtype: int64\n",
      "\n",
      "Severities for weather type Rain:\n",
      "Light       18506\n",
      "Moderate     4251\n",
      "Heavy        1370\n",
      "Name: Severity, dtype: int64\n",
      "\n",
      "Severities for weather type Fog:\n",
      "Moderate    1932\n",
      "Severe      1879\n",
      "Name: Severity, dtype: int64\n",
      "\n",
      "Severities for weather type Snow:\n",
      "Light       1570\n",
      "Moderate     561\n",
      "Heavy        175\n",
      "Name: Severity, dtype: int64\n",
      "\n",
      "Severities for weather type Precipitation:\n",
      "UNK    553\n",
      "Name: Severity, dtype: int64\n",
      "\n",
      "Severities for weather type Hail:\n",
      "Other    110\n",
      "Name: Severity, dtype: int64\n",
      "\n",
      "Severities for weather type Storm:\n",
      "Severe    172\n",
      "Name: Severity, dtype: int64\n",
      "\n",
      "Severities for weather type Cold:\n",
      "Severe    47\n",
      "Name: Severity, dtype: int64\n",
      "\n",
      "Severities for all types:\n",
      " Light       20076\n",
      "Moderate     6744\n",
      "Severe       2098\n",
      "Heavy        1545\n",
      "UNK           553\n",
      "Other         110\n",
      "Name: Severity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''Investigate weather types and declare numeric variables for them.\n",
    "Begin transitioning to the daily_weather DataFrame.'''\n",
    "print(weather_events.Type.value_counts())\n",
    "for weatherType in weather_events.Type.unique():\n",
    "    print('\\nSeverities for weather type ' + weatherType + ':')\n",
    "    print(weather_events[weather_events.Type==weatherType].Severity.value_counts())\n",
    "print('\\nSeverities for all types:\\n', weather_events.Severity.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rain: Light, Moderate, Heavy<br>\n",
    "Fog: Moderate, Severe<br>\n",
    "Snow: Light, Moderate, Heavy<br>\n",
    "Precipitation: UNK (we need to fix this)<br>\n",
    "Hail: Other<br>\n",
    "Storm: Severe<br>\n",
    "Cold: Severe<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_weather = weather_events.copy()\n",
    "\n",
    "DF_width = len(daily_weather.columns) #get this now before new columns added\n",
    "daily_weather['HailCode'] = (daily_weather.Type == 'Hail').map(int)\n",
    "daily_weather['StormCode'] = (daily_weather.Type == 'Storm').map(int)\n",
    "daily_weather['ColdCode'] = (daily_weather.Type == 'Cold').map(int)\n",
    "\n",
    "LightModerateHeavy = {'Light':1, 'Moderate':2, 'Heavy':3}\n",
    "daily_weather['RainCode'] =\\\n",
    "    daily_weather[daily_weather.Type=='Rain'].Severity.map(LightModerateHeavy)\n",
    "daily_weather.RainCode = daily_weather.RainCode.fillna(value=0)\n",
    "daily_weather['FogCode'] =\\\n",
    "    daily_weather[daily_weather.Type=='Fog'].Severity.map({'Moderate':1, 'Severe':2})\n",
    "daily_weather.FogCode = daily_weather.FogCode.fillna(value=0)\n",
    "daily_weather['SnowCode'] =\\\n",
    "    daily_weather[daily_weather.Type=='Snow'].Severity.map(LightModerateHeavy)\n",
    "daily_weather.SnowCode = daily_weather.SnowCode.fillna(value=0)\n",
    "FIRST_WEATHER_CODE = (daily_weather.columns)[DF_width] #needed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of \"Precipitation\" XOR \"UNK:\" 0\n"
     ]
    }
   ],
   "source": [
    "#Fix the \"Precipitation\" and \"UNK\" entries.\n",
    "PRECIP = 'Precipitation'; UNK = 'UNK'\n",
    "print('Count of \"' + PRECIP + '\" XOR \"' + UNK + ':\"', len(daily_weather\\\n",
    "    [((daily_weather.Type == PRECIP) &\n",
    "      (daily_weather.Severity != UNK)) |\n",
    "      ((daily_weather.Type != PRECIP) &\n",
    "      (daily_weather.Severity == UNK))].index)) #Perfect match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputing these events\n"
     ]
    }
   ],
   "source": [
    "print('\\nImputing these events')\n",
    "for airport in busiest_US_airports2018:\n",
    "    airport_indeces = daily_weather[daily_weather.Airport == airport].index\n",
    "    if airport_indeces.size > 0:\n",
    "        assert np.max(np.diff(airport_indeces)) == 1,\\\n",
    "            'Indexes misaligned for ' + str(airport)\n",
    "        weather_current_airport = daily_weather.loc[airport_indeces]\n",
    "        unknown_precip_indeces = weather_current_airport\\\n",
    "            [weather_current_airport.Type == PRECIP].index\n",
    "        if len(unknown_precip_indeces)==0:\n",
    "            print(airport, 'has no unknown precipitation')\n",
    "        else:\n",
    "            weather_before_indeces = unknown_precip_indeces-1\n",
    "            weather_after_indeces = unknown_precip_indeces+1\n",
    "            try:\n",
    "                weather_current_airport.loc[weather_before_indeces[0]]\n",
    "            except KeyError:\n",
    "                raise ValueError('First weather event at', airport, 'is unknown precip')\n",
    "            try:\n",
    "                weather_current_airport.loc[weather_after_indeces[-1]]\n",
    "            except KeyError:\n",
    "                raise ValueError('Last weather event at', airport, 'is unknown precip')\n",
    "            # Will need to code a workaround if either of these issues arise.\n",
    "        \n",
    "            # Impute based on averages from entries immediately before and after.\n",
    "            # Round up decimals to nearest integer.\n",
    "            imputation_values = np.ceil((\n",
    "                weather_current_airport.loc[weather_before_indeces, FIRST_WEATHER_CODE:].values\n",
    "                + weather_current_airport.loc[weather_after_indeces, FIRST_WEATHER_CODE:].values)/2).astype(int)\n",
    "            for i, index in enumerate(unknown_precip_indeces):\n",
    "                daily_weather.loc[index, FIRST_WEATHER_CODE:] = imputation_values[i]\n",
    "    else:\n",
    "        print(airport, 'has no entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Airport', 'Type', 'Severity', 'StartTimeLocal', 'EndTimeLocal',\n",
      "       'HailCode', 'StormCode', 'ColdCode', 'RainCode', 'FogCode', 'SnowCode'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(daily_weather.columns)\n",
    "daily_weather = daily_weather.drop(['Type', 'Severity'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest weather event: 23.1 hours\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze the lengths of the weather events.\n",
    "weather_duration = daily_weather.apply(\n",
    "    lambda row: (row['EndTimeLocal'] - row['StartTimeLocal']).seconds/3600, axis=1)\n",
    "longestEvent = max(weather_duration)\n",
    "print('Longest weather event: %.1f hours' % longestEvent) # <24 hours. Good.\n",
    "plt.hist(weather_duration, bins=int(longestEvent), color='b', align='left')\n",
    "plt.xlabel('Hours per event')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig(r'D:\\Springboard_DataSci\\Assignments\\Capstone_2--Airport_weather\\figures\\HoursPerWeatherEvent.png')\n",
    "plt.show() #Most events are < 2 hours, and almost all are < 8 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize events by date\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    daily_weather['StartDate'] = daily_weather.apply(lambda row: row['StartTimeLocal'].date(), axis=1)\n",
    "    daily_weather['EndDate'] = daily_weather.apply(lambda row: row['EndTimeLocal'].date(), axis=1)\n",
    "weather_starts = daily_weather.copy()\n",
    "weather_ends = daily_weather.copy()\n",
    "weather_starts = weather_starts.drop(['StartTimeLocal','EndTimeLocal','EndDate'], axis=1)\n",
    "weather_ends = weather_ends.drop(['StartTimeLocal','EndTimeLocal','StartDate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ColdCode  FogCode  HailCode  RainCode  SnowCode  StormCode\n",
      "Airport Date                                                                  \n",
      "ATL     2016-01-08         0      0.0         0       2.0       0.0          0\n",
      "        2016-01-09         0      2.0         0       1.0       0.0          0\n",
      "        2016-01-10         0      0.0         0       1.0       0.0          0\n",
      "        2016-01-15         0      2.0         0       3.0       0.0          0\n",
      "        2016-01-16         0      2.0         0       0.0       0.0          0\n"
     ]
    }
   ],
   "source": [
    "# Form a pivot table based on the highest precip code in each column per day.\n",
    "weather_starts = pd.pivot_table(data=weather_starts, index=['Airport','StartDate'], aggfunc=np.max)\n",
    "weather_ends = pd.pivot_table(data=weather_ends, index=['Airport','EndDate'], aggfunc=np.max)\n",
    "\n",
    "# Append weather_starts and weather_ends (the columns are the same).\n",
    "# We no longer need the daily_weather DF, so name the result that.\n",
    "daily_weather = weather_starts.append(weather_ends).sort_index()\n",
    "\n",
    "# Find the max over each date and rename the index.\n",
    "daily_weather = pd.pivot_table(data=daily_weather, index=['Airport','StartDate'], aggfunc=np.max)\n",
    "daily_weather.index.names = ['Airport','Date']\n",
    "print(daily_weather.head())\n",
    "\n",
    "weather_codes = pd.Series(daily_weather.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: --- 37.45 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Get the correlation matrix of data with X's features as columns.\n",
    "def corrMatrixAndMax(df, labels=weather_codes):\n",
    "    corr = df.corr()\n",
    "    n = corr.shape[0]\n",
    "    max_corr_ID = np.argmax(np.abs(corr) - np.eye(n))\n",
    "    return corr, np.unravel_index(max_corr_ID, [n,n])\n",
    "\n",
    "#Get the value, and row and column labels of a particular df coordinate. Rounding is arbitrary.\n",
    "def getCorrNameCoords(df, coordinates):\n",
    "    row = coordinates[0]; col = coordinates[1]\n",
    "    return round(df.iloc[row, col], 3), df.index[row], df.index[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, coords_max_corr = corrMatrixAndMax(daily_weather)\n",
    "print('\\nWeather code correlation matrix:\\n' + str(corr))\n",
    "print('Greatest correlation:', getCorrNameCoords(corr, coords_max_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hail and Snow have a correlation of 0.167. This is suspicious. Hail is a warm-weather event;\n",
    "snow is a cold-weather event. Let's look at the Hail and Snow codes to see how much overlap there is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SumByPair(df, label1, label2):\n",
    "    return df.groupby([label1, label2]).size().reset_index().rename(columns={0:'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nHail and snow code counts:\\n' + str(SumByPair(daily_weather, 'HailCode', 'SnowCode')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly half the Hail=1 codes are correlated with Snow>0 codes. This is a problem,\n",
    "and we need to investigate it. Let's take a look at these 35 days in the departure\n",
    "and arrival events DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
