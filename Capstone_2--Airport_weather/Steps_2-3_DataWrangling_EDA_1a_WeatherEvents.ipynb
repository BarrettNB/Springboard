{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Exploratory data analysis for the weather-airports project.\n",
    "\n",
    "Part 1a: Weather events\n",
    "\n",
    "Weather data: https://www.kaggle.com/sobhanmoosavi/us-weather-events\n",
    "Flight delays/cancellations: https://www.transtats.bts.gov/DL_SelectFields.asp\n",
    "Busiest airports: https://www.faa.gov/airports/planning_capacity/passenger_allcargo_stats/passenger/media/preliminary-cy18-commercial-service-enplanements.pdf\n",
    "\"\"\"\n",
    "\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pytz\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append('D:/Springboard_DataSci/Assignments/Lib')\n",
    "import TimeTracker\n",
    "\n",
    "START_YEAR = 2016\n",
    "END_YEAR = 2019\n",
    "save_data = True; save_data = False #whether to save the resulting data\n",
    "\n",
    "pd.options.mode.chained_assignment = None #turns off warnings for data replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing weather events CSV file\n"
     ]
    }
   ],
   "source": [
    "'''Data collection'''\n",
    "stopwatch = TimeTracker.TimeTracker()\n",
    "# Get all the data.\n",
    "path = r'D:\\Springboard_DataSci\\Assignments\\Capstone_2--Airport_weather\\data'\n",
    "os.chdir(path)\n",
    "print('Importing weather events CSV file')\n",
    "weather_events = pd.read_csv('US_WeatherEvents_2016-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any duplicates dropped? False\n"
     ]
    }
   ],
   "source": [
    "# Check for any duplicates.\n",
    "nRows = len(weather_events.index)\n",
    "weather_events.drop_duplicates(inplace=True)\n",
    "print('Any duplicates dropped?', len(weather_events.index)!=nRows) #No duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A source for the 2019 data was not available at this time, so I assume that the 2018\n",
    "busiest airport rankings are the same. Either way there should not have been a major\n",
    "dropoff in passenger numbers at the US's busiest airports between 2018 and 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the busiest airports in the US.\n",
    "busiest_US_airports2018 = ['ATL','LAX','ORD','DFW','DEN','JFK','SFO','SEA',\n",
    "                           'LAS','MCO','EWR','CLT','PHX','MIA','IAH','BOS',\n",
    "                           'MSP','FLL','DTW','PHL','LGA','BWI','SLC','SAN']\n",
    "busiest_US_airports2018 = pd.Series(\n",
    "    busiest_US_airports2018, index=range(1, len(busiest_US_airports2018)+1),\n",
    "    name='Airport')\n",
    "busiest_US_airports2018.index.name = 'Rank'\n",
    "if save_data:\n",
    "    busiest_US_airports2018.to_csv('busiest_US_airports2018.csv') #For Part 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "O'Hare weather events:\n",
      "Rain             1903\n",
      "Snow              566\n",
      "Fog               235\n",
      "Precipitation      44\n",
      "Hail               10\n",
      "Storm               8\n",
      "Cold                3\n",
      "Name: Type, dtype: int64\n",
      "Light       1859\n",
      "Moderate     578\n",
      "Severe       142\n",
      "Heavy        136\n",
      "UNK           44\n",
      "Other         10\n",
      "Name: Severity, dtype: int64\n",
      "Latitude, Longitude: [41.9875] [-87.9319]\n",
      "\n",
      "Newark weather events:\n",
      "Rain             1945\n",
      "Snow              297\n",
      "Fog               114\n",
      "Precipitation      33\n",
      "Hail               17\n",
      "Storm              10\n",
      "Cold                1\n",
      "Name: Type, dtype: int64\n",
      "Light       1648\n",
      "Moderate     504\n",
      "Heavy        131\n",
      "Severe        84\n",
      "UNK           33\n",
      "Other         17\n",
      "Name: Severity, dtype: int64\n",
      "Latitude, Longitude: [40.6827] [-74.1693]\n",
      "\n",
      "Phoenix weather events:\n",
      "Rain             401\n",
      "Fog               23\n",
      "Storm              9\n",
      "Cold               6\n",
      "Precipitation      2\n",
      "Hail               1\n",
      "Name: Type, dtype: int64\n",
      "Light       335\n",
      "Moderate     68\n",
      "Severe       23\n",
      "Heavy        13\n",
      "UNK           2\n",
      "Other         1\n",
      "Name: Severity, dtype: int64\n",
      "['US/Mountain']\n",
      "Latitude, Longitude: [33.4277] [-112.0038] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Explore the weather data.'''\n",
    "# Take a couple airports as a sample\n",
    "weather_ORD = weather_events[weather_events.AirportCode=='KORD']\n",
    "print('\\nO\\'Hare weather events:\\n' + str(weather_ORD.Type.value_counts()))\n",
    "print(weather_ORD.Severity.value_counts())\n",
    "print('Latitude, Longitude:', weather_ORD.LocationLat.unique(), weather_ORD.LocationLng.unique())\n",
    "\n",
    "weather_EWR = weather_events[weather_events.AirportCode=='KEWR']\n",
    "print('\\nNewark weather events:\\n' + str(weather_EWR.Type.value_counts()))\n",
    "print(weather_EWR.Severity.value_counts())\n",
    "print('Latitude, Longitude:', weather_EWR.LocationLat.unique(), weather_EWR.LocationLng.unique())\n",
    "\n",
    "# Need to see what's going on with Phoenix's time zones\n",
    "weather_PHX = weather_events[weather_events.AirportCode=='KPHX']\n",
    "print('\\nPhoenix weather events:\\n' + str(weather_PHX.Type.value_counts()))\n",
    "print(weather_PHX.Severity.value_counts()) #Warmer, drier climate\n",
    "print(weather_PHX.TimeZone.unique()) #Just 'US/Mountain'. PHX is standard time year-round.\n",
    "print('Latitude, Longitude:', weather_PHX.LocationLat.unique(), weather_PHX.LocationLng.unique(), '\\n')\n",
    "weather_events.loc[(weather_events.AirportCode=='KPHX'), 'TimeZone'] = 'US/Arizona'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the airports we need.\n",
    "ICAO_codes = ('K'+busiest_US_airports2018).to_list()\n",
    "weather_events.drop(weather_events.index[np.where(~weather_events.AirportCode.isin(ICAO_codes))[0]], inplace=True)\n",
    "\n",
    "# Recast the 4-lettered ICAO-code index into the 3-lettered IATA codes.\n",
    "weather_events.rename(columns={'AirportCode': 'Airport'}, inplace=True)\n",
    "weather_events.Airport = weather_events.Airport.apply(\n",
    "    lambda prefix: prefix[1:])\n",
    "\n",
    "# Replace the useless index numbers with default indexing.\n",
    "weather_events = weather_events.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['EventId', 'Type', 'Severity', 'StartTime(UTC)', 'EndTime(UTC)',\n",
      "       'TimeZone', 'Airport', 'LocationLat', 'LocationLng', 'City', 'County',\n",
      "       'State', 'ZipCode'],\n",
      "      dtype='object')\n",
      "None \n",
      " Index(['TimeZone', 'Airport', 'LocationLat', 'LocationLng', 'City', 'County',\n",
      "       'State'],\n",
      "      dtype='object')\n",
      "                         City State     TimeZone  LocationLat  LocationLng\n",
      "Airport                                                                   \n",
      "JFK                   Jamaica    NY   US/Eastern      40.6392     -73.7639\n",
      "ORD               Bensenville    IL   US/Central      41.9875     -87.9319\n",
      "DTW                   Detroit    MI   US/Eastern      42.2314     -83.3308\n",
      "FLL           Fort Lauderdale    FL   US/Eastern      26.0787     -80.1622\n",
      "SLC            Salt Lake City    UT  US/Mountain      40.7707    -111.9650\n",
      "BOS               East Boston    MA   US/Eastern      42.3606     -71.0097\n",
      "SAN                 San Diego    CA   US/Pacific      32.7339    -117.1845\n",
      "DEN                    Denver    CO  US/Mountain      39.8466    -104.6562\n",
      "MCO                   Orlando    FL   US/Eastern      28.4183     -81.3241\n",
      "DFW                    Dallas    TX   US/Central      32.8974     -97.0220\n",
      "EWR                    Newark    NJ   US/Eastern      40.6827     -74.1693\n",
      "LAS                 Las Vegas    NV   US/Pacific      36.0719    -115.1634\n",
      "LAX               Los Angeles    CA   US/Pacific      33.9382    -118.3865\n",
      "ATL                   Atlanta    GA   US/Eastern      33.6301     -84.4418\n",
      "SEA                   Seattle    WA   US/Pacific      47.4447    -122.3144\n",
      "BWI                 Baltimore    MD   US/Eastern      39.1733     -76.6840\n",
      "SFO             San Francisco    CA   US/Pacific      37.6196    -122.3656\n",
      "CLT      Township 2 Berryhill    NC   US/Eastern      35.2225     -80.9543\n",
      "LGA                  Flushing    NY   US/Eastern      40.7794     -73.8803\n",
      "PHL              Philadelphia    PA   US/Eastern      39.8733     -75.2268\n",
      "MSP               Minneapolis    MN   US/Central      44.8854     -93.2313\n",
      "PHX                   Phoenix    AZ   US/Arizona      33.4277    -112.0038\n",
      "MIA                     Miami    FL   US/Eastern      25.7880     -80.3169\n",
      "IAH                   Houston    TX   US/Central      29.9844     -95.3607\n"
     ]
    }
   ],
   "source": [
    "# Get the details on our airports\n",
    "print(weather_events.columns)\n",
    "unique_airports_weather = weather_events.loc[:, 'TimeZone':'State'].drop_duplicates()\n",
    "print(unique_airports_weather.index.name, '\\n', unique_airports_weather.columns)\n",
    "unique_airports_weather = unique_airports_weather.drop('County', axis=1)\n",
    "unique_airports_weather = unique_airports_weather.set_index('Airport')\n",
    "unique_airports_weather = unique_airports_weather[['City','State','TimeZone','LocationLat','LocationLng']]\n",
    "print(unique_airports_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns: Index(['Type', 'Severity', 'StartTime(UTC)', 'EndTime(UTC)', 'TimeZone',\n",
      "       'Airport'],\n",
      "      dtype='object')\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Latitude and longitudes check out. Let's trim extraneous columns.'''\n",
    "weather_events = weather_events.drop(['EventId','LocationLat','LocationLng',\n",
    "                                      'County','ZipCode','City','State'], axis=1)\n",
    "print('Remaining columns:', weather_events.columns)\n",
    "\n",
    "# '''Get the weather data times into datetime format.'''\n",
    "print(type(weather_events.iloc[0].loc['StartTime(UTC)']))\n",
    "print(type(weather_events.iloc[0].loc['EndTime(UTC)'])) #Both are strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting weather start times to local time zones\n",
      "Converting weather end times to local time zones\n"
     ]
    }
   ],
   "source": [
    "# Convert datetimes and timezones to the right types of objects.\n",
    "weather_events['StartTime(UTC)'] = pd.to_datetime(weather_events['StartTime(UTC)']).dt.tz_localize('utc')\n",
    "weather_events['EndTime(UTC)'] = pd.to_datetime(weather_events['EndTime(UTC)']).dt.tz_localize('utc')\n",
    "weather_events['TimeZone'] = weather_events['TimeZone'].map(pytz.timezone)\n",
    "\n",
    "# Localize the times to their respective time zones.\n",
    "print('Converting weather start times to local time zones')\n",
    "weather_events['StartTimeLocal'] = weather_events.apply(\n",
    "    lambda row: row['StartTime(UTC)'].tz_convert(row['TimeZone']), axis=1)\n",
    "print('Converting weather end times to local time zones')\n",
    "weather_events['EndTimeLocal'] = weather_events.apply(\n",
    "    lambda row: row['EndTime(UTC)'].tz_convert(row['TimeZone']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing entries completely outside the relevant year(s)\n",
      "Remaining events count: 49812\n"
     ]
    }
   ],
   "source": [
    "# We no longer need data outside the relevant year. Remove them and reset the index.\n",
    "# Irrelevant if all years are selected.\n",
    "print('Removing entries completely outside the relevant year(s)')\n",
    "weather_events = weather_events.drop(weather_events[weather_events.apply(\n",
    "    lambda row: (row['StartTimeLocal'].year > END_YEAR)\\\n",
    "              | (row['EndTimeLocal'].year < START_YEAR), axis=1)].index)\n",
    "print('Remaining events count:', len(weather_events.index))\n",
    "weather_events = weather_events.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Type', 'Severity', 'StartTime(UTC)', 'EndTime(UTC)', 'TimeZone',\n",
      "       'Airport', 'StartTimeLocal', 'EndTimeLocal'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Cut the columns just down to the ones we need and reorder them.\n",
    "print(weather_events.columns)\n",
    "weather_events = weather_events[['Airport','Type','Severity','StartTimeLocal','EndTimeLocal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events that spanned New Year's 2016 or 2020\n",
      "Empty DataFrame\n",
      "Columns: [Airport, Type, Severity, StartTimeLocal, EndTimeLocal]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many events rolled over New Year's at the endpoints.\n",
    "print('Events that spanned New Year\\'s', START_YEAR, 'or', END_YEAR+1)\n",
    "events_outside_our_years = weather_events.apply(\n",
    "    lambda row: (row['StartTimeLocal'].year < START_YEAR)\\\n",
    "        | (row['EndTimeLocal'].year > END_YEAR), axis=1)\n",
    "print(weather_events[events_outside_our_years]) #None!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the paper which us-weather-events.csv is based on, Hail is \"solid precipitation\n",
    "including ice pellets and hail.\" This is a problem. Sleet rarely measures more than a couple\n",
    "millimeters in diameter, but hail can grow up to several centimeters in diameter, making\n",
    "takeoff and landing too dangerous. Unfortunately, the paper combines these two different types\n",
    "of precipitation into one.\n",
    "\n",
    "It also defines Storm as \"the extremely windy condition, where the wind speed is at least\n",
    "60kmh [sic].\" That is about 40 mph. We need to rename \"Storm\" to \"Wind\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_events['Type'].replace('Storm', 'Wind', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can discern between hail and sleet in our dataset. First, get a list of every\n",
    "\"hail\" event and see what is immediately around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hail events: 210\n"
     ]
    }
   ],
   "source": [
    "hail_events = weather_events[weather_events.Type=='Hail']\n",
    "hailEventIndices = weather_events[weather_events.Type=='Hail'].index\n",
    "n_hail = len(hailEventIndices)\n",
    "print('Number of hail events:', n_hail)\n",
    "assert hailEventIndices[0]!=0 and hailEventIndices[-1]!=len(hailEventIndices)-1,\\\n",
    "    'Very first or last event is hail, need to account for this'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how long before the first immediately prior and following events.\n",
    "hail_prior_events = weather_events.loc[hailEventIndices-1].drop('StartTimeLocal', axis=1) #drop for simplicity\n",
    "hail_next_events = weather_events.loc[hailEventIndices+1].drop('EndTimeLocal', axis=1) #drop for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All events with hail codes have the same airport as their prior codes? True\n",
      "All events with hail codes have the same airport as their following codes? True\n"
     ]
    }
   ],
   "source": [
    "# Some of these might be between different airports. Need to check this.\n",
    "print('All events with hail codes have the same airport as their prior codes?',\n",
    "      all([hail_events['Airport'].iloc[i] == hail_prior_events['Airport'].iloc[i] for i in range(n_hail)]))\n",
    "print('All events with hail codes have the same airport as their following codes?',\n",
    "      all([hail_events['Airport'].iloc[i] == hail_next_events['Airport'].iloc[i] for i in range(n_hail)]))\n",
    "# Good, no discrepancies. Next, let's check the time gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hailStartTimeGap values:\n",
      "0 days 00:00:00    150\n",
      "0 days 00:04:00      2\n",
      "0 days 00:06:00      1\n",
      "0 days 00:07:00      1\n",
      "0 days 00:10:00      2\n",
      "0 days 00:13:00      1\n",
      "0 days 00:25:00      2\n",
      "0 days 00:28:00      1\n",
      "0 days 00:32:00      1\n",
      "0 days 00:33:00      1\n",
      "0 days 00:40:00      1\n",
      "0 days 00:43:00      1\n",
      "0 days 00:50:00      1\n",
      "0 days 00:54:00      2\n",
      "0 days 00:58:00      1\n",
      "0 days 01:00:00      1\n",
      "0 days 01:05:00      1\n",
      "0 days 01:20:00      1\n",
      "0 days 01:27:00      1\n",
      "0 days 01:40:00      1\n",
      "0 days 02:02:00      1\n",
      "0 days 02:15:00      1\n",
      "0 days 02:19:00      1\n",
      "0 days 02:27:00      1\n",
      "0 days 02:29:00      1\n",
      "0 days 03:07:00      1\n",
      "0 days 03:53:00      1\n",
      "0 days 04:00:00      1\n",
      "0 days 04:47:00      2\n",
      "0 days 05:25:00      1\n",
      "0 days 05:40:00      1\n",
      "0 days 05:53:00      1\n",
      "0 days 06:00:00      1\n",
      "0 days 12:38:00      1\n",
      "0 days 14:00:00      1\n",
      "0 days 21:41:00      1\n",
      "0 days 22:00:00      1\n",
      "0 days 23:00:00      1\n",
      "1 days 07:37:00      1\n",
      "1 days 07:39:00      1\n",
      "1 days 08:27:00      1\n",
      "1 days 16:33:00      1\n",
      "1 days 23:41:00      1\n",
      "1 days 23:46:00      1\n",
      "2 days 03:33:00      1\n",
      "2 days 09:12:00      1\n",
      "2 days 13:23:00      1\n",
      "2 days 13:41:00      1\n",
      "2 days 15:00:00      1\n",
      "2 days 22:00:00      1\n",
      "3 days 00:55:00      1\n",
      "3 days 21:37:00      1\n",
      "4 days 18:58:00      1\n",
      "5 days 17:48:00      1\n",
      "6 days 00:27:00      1\n",
      "7 days 17:22:00      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "hailStartTimeGap = pd.Series([hail_events['StartTimeLocal'].iloc[i]\\\n",
    "                              - hail_prior_events['EndTimeLocal'].iloc[i] for i in range(n_hail)])\n",
    "hailEndTimeGap = pd.Series([hail_next_events['StartTimeLocal'].iloc[i]\\\n",
    "                            - hail_events['EndTimeLocal'].iloc[i] for i in range(n_hail)])\n",
    "print('\\nhailStartTimeGap values:\\n' + str(hailStartTimeGap.value_counts().sort_index()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hailEndTimeGap values:\n",
      "0 days 00:00:00    188\n",
      "0 days 00:04:00      1\n",
      "0 days 00:06:00      1\n",
      "0 days 00:08:00      1\n",
      "0 days 00:13:00      1\n",
      "0 days 00:16:00      1\n",
      "0 days 00:25:00      1\n",
      "0 days 00:43:00      1\n",
      "0 days 00:45:00      1\n",
      "0 days 00:54:00      1\n",
      "0 days 01:08:00      1\n",
      "0 days 01:12:00      1\n",
      "0 days 02:06:00      1\n",
      "0 days 03:00:00      1\n",
      "0 days 03:07:00      1\n",
      "0 days 03:54:00      1\n",
      "0 days 04:58:00      1\n",
      "0 days 05:51:00      1\n",
      "0 days 06:32:00      1\n",
      "0 days 08:55:00      1\n",
      "0 days 09:05:00      1\n",
      "1 days 10:07:00      1\n",
      "2 days 21:41:00      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\nhailEndTimeGap values:\\n' + str(hailEndTimeGap.value_counts().sort_index()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of \"StartTimeGap\" and nearly all of \"EndTimeGap\"s are 0. We need to make a decision\n",
    "of when the cutoff will be for associating the current event with the next/prior one.\n",
    "\n",
    "To start, let's sample just the ones with startTimeGaps and endTimeGaps of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prior event codes with zero time gap:\n",
      "Rain             101\n",
      "Snow              40\n",
      "Precipitation      1\n",
      "Fog                1\n",
      "Name: Type, dtype: int64\n",
      "\n",
      "Next event codes with zero time gap:\n",
      "Rain             107\n",
      "Snow              33\n",
      "Wind               1\n",
      "Precipitation      1\n",
      "Fog                1\n",
      "Name: Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "hours_StartTimeGap = hailStartTimeGap.apply(\n",
    "    lambda x: timedelta.total_seconds(x)/3600)\n",
    "hours_EndTimeGap = hailEndTimeGap.apply(\n",
    "    lambda x: timedelta.total_seconds(x)/3600)\n",
    "indeces_ZeroTimeGap = (hours_StartTimeGap[hours_StartTimeGap==0].index).intersection(\n",
    "    hours_EndTimeGap[hours_EndTimeGap==0].index)\n",
    "print('\\nPrior event codes with zero time gap:\\n' + str(\n",
    "    hail_prior_events.iloc[indeces_ZeroTimeGap]['Type'].value_counts()))\n",
    "print('\\nNext event codes with zero time gap:\\n' + str(\n",
    "    hail_next_events.iloc[indeces_ZeroTimeGap]['Type'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''Most of \"StartTimeGap\" and nearly all of \"EndTimeGap\"s are 0. We need to make a decision\n",
    "of when the cutoff will be for associating the current event with the next/prior one.\n",
    "\n",
    "To start, let's consider just the ones with startTimeGaps and endTimeGaps of 0.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_StartTimeGap = hailStartTimeGap.apply(\n",
    "    lambda x: timedelta.total_seconds(x)/3600)\n",
    "hours_EndTimeGap = hailEndTimeGap.apply(\n",
    "    lambda x: timedelta.total_seconds(x)/3600)\n",
    "indeces_ZeroTimeGap = hours_StartTimeGap[hours_StartTimeGap==0].index.intersection(\n",
    "    hours_EndTimeGap[hours_EndTimeGap==0].index)\n",
    "\n",
    "hail_prior_events_ZeroTimeGap = hail_prior_events.iloc[indeces_ZeroTimeGap]\n",
    "hail_next_events_ZeroTimeGap = hail_next_events.iloc[indeces_ZeroTimeGap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prior event codes with zero time gap:\n",
      "Rain             101\n",
      "Snow              40\n",
      "Precipitation      1\n",
      "Fog                1\n",
      "Name: Type, dtype: int64\n",
      "\n",
      "Next event codes with zero time gap:\n",
      "Rain             107\n",
      "Snow              33\n",
      "Wind               1\n",
      "Precipitation      1\n",
      "Fog                1\n",
      "Name: Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\nPrior event codes with zero time gap:\\n' + str(\n",
    "    hail_prior_events_ZeroTimeGap['Type'].value_counts()))\n",
    "print('\\nNext event codes with zero time gap:\\n' + str(\n",
    "    hail_next_events_ZeroTimeGap['Type'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the surrounding codes are Rain, but a few are Snow. This doesn't give us\n",
    "any clear indication yet between sleet or hail.\n",
    "\n",
    "However, we can make some assumptions. First, if the weather code immediately prior\n",
    "or after is snow, this event marked \"hail\" is actually sleet. Let's start attempting\n",
    "to classify what the Hail code actually means. To start, we populate that entire\n",
    "column with NaN's, with our goal to accurately reduce them to zero. Assumptions\n",
    "are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAIL = 1\n",
    "SLEET = 0\n",
    "REM_NANS = 'Remaining unassigned Hail codes:'\n",
    "AHC = 'ActualHailCode' #so I don't have to keep rewriting this\n",
    "\n",
    "def hailCodeNaNs(df):\n",
    "    return df[AHC].isna().sum()\n",
    "\n",
    "def histHailCount(df):\n",
    "    month = df['Month']\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(month-0.5, bins=12, range=[0,12], align='right', color='r')\n",
    "    ax.set_xlabel('Month')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Hail codes by month')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting unassigned Hail codes: 210\n",
      "Remaining unassigned Hail codes: 198\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "hail_events[AHC] = np.nan\n",
    "hail_events['Month'] = hail_events['StartTimeLocal'].apply(lambda t: t.month)\n",
    "print('Starting unassigned Hail codes:', hailCodeNaNs(hail_events)) #Starting count: 110\n",
    "\n",
    "#1. Any Hail code in June, July, August, or September is probably hail.\n",
    "hail_events[AHC][(hail_events['Month'] >= 6) & (hail_events['Month'] <= 9)] = HAIL\n",
    "print(REM_NANS, hailCodeNaNs(hail_events)) #Remaining count: 198 (was 99; September excluded)\n",
    "nAn_indeces = hail_events[hail_events[AHC].isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining unassigned Hail codes: 122\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "#2. Any Hail code within six hours of a Snow code is probably sleet.\n",
    "time_gap = 6\n",
    "events_prior = hail_prior_events.loc[nAn_indeces - 1]\n",
    "events_next = hail_next_events.loc[nAn_indeces + 1]\n",
    "events_prior.set_index(events_prior.index + 1, inplace=True)\n",
    "events_next.set_index(events_next.index - 1, inplace=True)\n",
    "\n",
    "boolean_prior = (events_prior['EndTimeLocal'] + timedelta(hours=time_gap) >=\\\n",
    "    hail_events[hail_events[AHC].isna()]['StartTimeLocal']) &\\\n",
    "    (events_prior['Type'] == 'Snow')\n",
    "boolean_next = (events_next['StartTimeLocal'] - timedelta(hours=time_gap) <=\\\n",
    "    hail_events[hail_events[AHC].isna()]['EndTimeLocal']) &\\\n",
    "    (events_next['Type'] == 'Snow')\n",
    "hail_events[AHC].loc[(boolean_prior | boolean_next)\\\n",
    "                     [(boolean_prior | boolean_next)].index] = SLEET\n",
    "print(REM_NANS, hailCodeNaNs(hail_events)) #Remaining count: 69   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Histogram of remaining NaN's\n",
    "histHailCount(hail_events[hail_events[AHC].isna()])\n",
    "#Lots remaining in the winter months. These are probably sleet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining unassigned Hail codes: 57\n",
      "Airports and months of remaining unassigned hail codes:\n",
      "Month    3   4   5   10\n",
      "Airport                \n",
      "ATL       3   0   0   0\n",
      "BOS       1   0   0   0\n",
      "BWI       3   4   1   0\n",
      "CLT       5   2   0   0\n",
      "DEN       0   1   3   1\n",
      "DFW       1   0   0   0\n",
      "DTW       0   6   1   1\n",
      "EWR       6   0   0   0\n",
      "JFK       1   0   0   0\n",
      "LGA       3   0   0   0\n",
      "MCO       1   0   0   0\n",
      "MSP       1   4   0   0\n",
      "ORD       0   1   0   0\n",
      "PHL       1   0   0   0\n",
      "SLC       1   1   4   0\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "#3. Any remaining Hail code in November, December, January, or February is probably sleet.\n",
    "hail_events[AHC][hail_events[AHC].isna() & (\n",
    "    (hail_events['Month'] >= 11) | (hail_events['Month'] <= 2))] = SLEET\n",
    "print(REM_NANS, hailCodeNaNs(hail_events)) #Remaining count: 57 (was 25, didn't include November)\n",
    "print('Airports and months of remaining unassigned hail codes:')\n",
    "remaining_hail_unknowns = hail_events[hail_events[AHC].isna()][['Airport','Month']]\n",
    "remaining_hail_unknowns_crosstab = pd.crosstab(\n",
    "    index=remaining_hail_unknowns['Airport'], columns=remaining_hail_unknowns['Month'])\n",
    "print(remaining_hail_unknowns_crosstab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all of the remaining events are in March or April, when weather is highly variable. We have 57 of these codes to deal with, which would be a lot to manage by hand, yet these are a tiny fraction of the total number of codes. Let's interpolate by each city's climate by month. We use the following rule of thumb: Temperatures of at least 50F probably correspond to hail, and those below 50 probably correspond to sleet. All records come from NOAA climate data through Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Remaining unassigned Hail codes: 0\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "daily_means = pd.DataFrame({'ATL':[54, 62, 70, 63], 'BOS':[38, 48, 58, 54],\n",
    "                            'BWI':[46, 57, 66, 60], 'CLT':[51, 59, 67, 60],\n",
    "                            'DEN':[40, 47, 57, 51], 'DFW':[57, 65, 73, 67],\n",
    "                            'DTW':[46, 59, 70, 62], 'EWR':[51, 62, 72, 65],\n",
    "                            'JFK':[50, 61, 71, 64], 'LGA':[50, 61, 71, 64],\n",
    "                            'MCO':[67, 71, 77, 76], 'MSP':[33, 48, 59, 49],\n",
    "                            'ORD':[39, 51, 61, 54], 'PHL':[53, 64, 74, 67],\n",
    "                            'SLC':[54, 62, 72, 65]},\n",
    "                           columns=remaining_hail_unknowns_crosstab.index,\n",
    "                           index=remaining_hail_unknowns_crosstab.columns).T\n",
    "\n",
    "remaining_hail_unknowns[AHC] = remaining_hail_unknowns.apply(\n",
    "    lambda row: int(daily_means.loc[row.Airport, row.Month] >= 50), axis=1)\n",
    "hail_events.loc[remaining_hail_unknowns.index, AHC] = remaining_hail_unknowns[AHC]\n",
    "\n",
    "print('\\n', REM_NANS, hailCodeNaNs(hail_events)) #Remaining count: 0\n",
    "\n",
    "#Update the full DataFrame with these imputed data.\n",
    "weather_events.loc[(hail_events[hail_events[AHC]==SLEET]).index, 'Type'] = 'Sleet'\n",
    "weather_events.reset_index(inplace=True) #for the two CLT dropped codes\n",
    "#These codes were already \"Hail\", so there is nothing to impute there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of some variables that are no longer needed.\n",
    "del(hailEndTimeGap, hailEventIndices, hailStartTimeGap, hail_events, events_next,\n",
    "    hail_next_events, hail_next_events_ZeroTimeGap, events_prior, hail_prior_events,\n",
    "    hail_prior_events_ZeroTimeGap, hours_EndTimeGap, hours_StartTimeGap, nAn_indeces, nRows,\n",
    "    n_hail, ICAO_codes, REM_NANS, events_outside_our_years, time_gap, unique_airports_weather,\n",
    "    weather_EWR, weather_ORD, weather_PHX, boolean_prior, boolean_next, HAIL, SLEET,\n",
    "    remaining_hail_unknowns, remaining_hail_unknowns_crosstab, daily_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate weather types and declare numeric variables for them.\n",
    "Begin transitioning to the daily_weather DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rain             37112\n",
      "Fog               6128\n",
      "Snow              5121\n",
      "Precipitation      786\n",
      "Cold               238\n",
      "Wind               217\n",
      "Sleet              151\n",
      "Hail                59\n",
      "Name: Type, dtype: int64\n",
      "\n",
      "Severities for weather type Rain:\n",
      "Light       28594\n",
      "Moderate     6538\n",
      "Heavy        1980\n",
      "Name: Severity, dtype: int64\n",
      "\n",
      "Severities for weather type Fog:\n",
      "Moderate    3219\n",
      "Severe      2909\n",
      "Name: Severity, dtype: int64\n",
      "\n",
      "Severities for weather type Snow:\n",
      "Light       3597\n",
      "Moderate    1183\n",
      "Heavy        341\n",
      "Name: Severity, dtype: int64\n",
      "\n",
      "Severities for weather type Precipitation:\n",
      "UNK    786\n",
      "Name: Severity, dtype: int64\n",
      "\n",
      "Severities for weather type Sleet:\n",
      "Other    151\n",
      "Name: Severity, dtype: int64\n",
      "\n",
      "Severities for weather type Wind:\n",
      "Severe    217\n",
      "Name: Severity, dtype: int64\n",
      "\n",
      "Severities for weather type Cold:\n",
      "Severe    238\n",
      "Name: Severity, dtype: int64\n",
      "\n",
      "Severities for weather type Hail:\n",
      "Other    59\n",
      "Name: Severity, dtype: int64\n",
      "\n",
      "Severities for all types:\n",
      " Light       32191\n",
      "Moderate    10940\n",
      "Severe       3364\n",
      "Heavy        2321\n",
      "UNK           786\n",
      "Other         210\n",
      "Name: Severity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "severity_value_counts = weather_events.Type.value_counts()\n",
    "print(severity_value_counts)\n",
    "severity_value_counts.to_csv('severity_value_counts.csv')\n",
    "for weatherType in weather_events.Type.unique():\n",
    "    print('\\nSeverities for weather type ' + weatherType + ':')\n",
    "    print(weather_events[weather_events.Type==weatherType].Severity.value_counts())\n",
    "print('\\nSeverities for all types:\\n', weather_events.Severity.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rain: Light, Moderate, Heavy<br>\n",
    "Fog: Moderate, Severe<br>\n",
    "Snow: Light, Moderate, Heavy<br>\n",
    "Precipitation: UNK (we need to fix this)<br>\n",
    "Hail: Other<br>\n",
    "Sleet: Other<br>\n",
    "Storm: Severe<br>\n",
    "Cold: Severe<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_weather = weather_events.copy()\n",
    "\n",
    "DF_width = len(daily_weather.columns) #get this now before new columns added\n",
    "daily_weather['HailCode'] = (daily_weather.Type == 'Hail').map(int)\n",
    "daily_weather['SleetCode'] = (daily_weather.Type == 'Sleet').map(int)\n",
    "daily_weather['HiWindCode'] = (daily_weather.Type == 'Wind').map(int) #See later\n",
    "daily_weather['ColdCode'] = (daily_weather.Type == 'Cold').map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "LightModerateHeavy = {'Light':1, 'Moderate':2, 'Heavy':3}\n",
    "daily_weather['RainCode'] =\\\n",
    "    daily_weather[daily_weather.Type=='Rain'].Severity.map(LightModerateHeavy)\n",
    "daily_weather.RainCode = daily_weather.RainCode.fillna(value=0)\n",
    "daily_weather['FogCode'] =\\\n",
    "    daily_weather[daily_weather.Type=='Fog'].Severity.map({'Moderate':1, 'Severe':2})\n",
    "daily_weather.FogCode = daily_weather.FogCode.fillna(value=0)\n",
    "daily_weather['SnowCode'] =\\\n",
    "    daily_weather[daily_weather.Type=='Snow'].Severity.map(LightModerateHeavy)\n",
    "daily_weather.SnowCode = daily_weather.SnowCode.fillna(value=0)\n",
    "FIRST_WEATHER_CODE = (daily_weather.columns)[DF_width] #needed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of \"Precipitation\" XOR \"UNK:\" 0\n"
     ]
    }
   ],
   "source": [
    "#Fix the \"Precipitation\" and \"UNK\" entries.\n",
    "PRECIP = 'Precipitation'; UNK = 'UNK'\n",
    "print('Count of \"' + PRECIP + '\" XOR \"' + UNK + ':\"', len(daily_weather\\\n",
    "    [((daily_weather.Type == PRECIP) &\n",
    "      (daily_weather.Severity != UNK)) |\n",
    "      ((daily_weather.Type != PRECIP) &\n",
    "      (daily_weather.Severity == UNK))].index)) #Perfect match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputing these events\n"
     ]
    }
   ],
   "source": [
    "print('\\nImputing these events')\n",
    "for airport in busiest_US_airports2018:\n",
    "    airport_indeces = daily_weather[daily_weather.Airport == airport].index\n",
    "    if airport_indeces.size > 0:\n",
    "        assert np.max(np.diff(airport_indeces)) == 1,\\\n",
    "            'Indexes misaligned for ' + str(airport)\n",
    "        weather_current_airport = daily_weather.loc[airport_indeces]\n",
    "        unknown_precip_indeces = weather_current_airport\\\n",
    "            [weather_current_airport.Type == PRECIP].index\n",
    "        if len(unknown_precip_indeces)==0:\n",
    "            print(airport, 'has no unknown precipitation')\n",
    "        else:\n",
    "            weather_before_indeces = unknown_precip_indeces-1\n",
    "            weather_after_indeces = unknown_precip_indeces+1\n",
    "            try:\n",
    "                weather_current_airport.loc[weather_before_indeces[0]]\n",
    "            except KeyError:\n",
    "                raise ValueError('First weather event at', airport, 'is unknown precip')\n",
    "            try:\n",
    "                weather_current_airport.loc[weather_after_indeces[-1]]\n",
    "            except KeyError:\n",
    "                raise ValueError('Last weather event at', airport, 'is unknown precip')\n",
    "            # Will need to code a workaround if either of these issues arise.\n",
    "        \n",
    "            # Impute based on averages from entries immediately before and after.\n",
    "            # Round up decimals to nearest integer.\n",
    "            imputation_values = np.ceil((\n",
    "                weather_current_airport.loc[weather_before_indeces, FIRST_WEATHER_CODE:].values\n",
    "                + weather_current_airport.loc[weather_after_indeces, FIRST_WEATHER_CODE:].values)/2).astype(int)\n",
    "            for i, index in enumerate(unknown_precip_indeces):\n",
    "                daily_weather.loc[index, FIRST_WEATHER_CODE:] = imputation_values[i]\n",
    "    else:\n",
    "        print(airport, 'has no entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'Airport', 'Type', 'Severity', 'StartTimeLocal',\n",
      "       'EndTimeLocal', 'HailCode', 'SleetCode', 'HiWindCode', 'ColdCode',\n",
      "       'RainCode', 'FogCode', 'SnowCode'],\n",
      "      dtype='object')\n",
      "Longest weather event: 23.1 hours\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(daily_weather.columns)\n",
    "daily_weather = daily_weather.drop(['Type', 'Severity'], axis=1)\n",
    "\n",
    "# Analyze the lengths of the weather events.\n",
    "weather_duration = daily_weather.apply(\n",
    "    lambda row: (row['EndTimeLocal'] - row['StartTimeLocal']).seconds/3600, axis=1)\n",
    "longestEvent = max(weather_duration)\n",
    "print('Longest weather event: %.1f hours' % longestEvent) # <24 hours. Good.\n",
    "plt.hist(weather_duration, bins=int(longestEvent), color='b', align='left')\n",
    "plt.xlabel('Hours per event')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig(r'D:\\Springboard_DataSci\\Assignments\\Capstone_2--Airport_weather\\figures\\HoursPerWeatherEvent.png')\n",
    "plt.show() #Most events are < 2 hours, and almost all are < 8 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize events by date\n",
    "warnings.simplefilter('ignore')\n",
    "daily_weather['StartDate'] = daily_weather.apply(lambda row: row['StartTimeLocal'].date(), axis=1)\n",
    "daily_weather['EndDate'] = daily_weather.apply(lambda row: row['EndTimeLocal'].date(), axis=1)\n",
    "weather_starts = daily_weather.copy()\n",
    "weather_ends = daily_weather.copy()\n",
    "weather_starts = weather_starts.drop(['StartTimeLocal','EndTimeLocal','EndDate'], axis=1)\n",
    "weather_ends = weather_ends.drop(['StartTimeLocal','EndTimeLocal','StartDate'], axis=1)\n",
    "\n",
    "# Form a pivot table based on the highest precip code in each column per day.\n",
    "weather_starts = pd.pivot_table(data=weather_starts, index=['Airport','StartDate'], aggfunc=np.max)\n",
    "weather_ends = pd.pivot_table(data=weather_ends, index=['Airport','EndDate'], aggfunc=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ColdCode  FogCode  HailCode  HiWindCode  RainCode  \\\n",
      "Airport Date                                                            \n",
      "ATL     2016-01-08         0      0.0         0           0       2.0   \n",
      "        2016-01-09         0      2.0         0           0       1.0   \n",
      "        2016-01-10         0      0.0         0           0       1.0   \n",
      "        2016-01-15         0      2.0         0           0       3.0   \n",
      "        2016-01-16         0      2.0         0           0       0.0   \n",
      "\n",
      "                    SleetCode  SnowCode  index  \n",
      "Airport Date                                    \n",
      "ATL     2016-01-08          0       0.0  25999  \n",
      "        2016-01-09          0       0.0  26003  \n",
      "        2016-01-10          0       0.0  26004  \n",
      "        2016-01-15          0       0.0  26022  \n",
      "        2016-01-16          0       0.0  26024  \n"
     ]
    }
   ],
   "source": [
    "# Append weather_starts and weather_ends (the columns are the same).\n",
    "# We no longer need the daily_weather DF, so name the result that.\n",
    "daily_weather = weather_starts.append(weather_ends).sort_index()\n",
    "\n",
    "# Find the max over each date and rename the index.\n",
    "daily_weather = pd.pivot_table(data=daily_weather, index=['Airport','StartDate'], aggfunc=np.max)\n",
    "daily_weather.index.names = ['Airport','Date']\n",
    "print(daily_weather.head())\n",
    "\n",
    "weather_codes = pd.Series(daily_weather.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the correlation matrix of data with X's features as columns. Rounding is arbitrary.\n",
    "def corrMatrixAndMax(df, labels=weather_codes, trims=0):\n",
    "    corr = df.corr().round(3)\n",
    "    if trims>0:\n",
    "        corr = corr.iloc[:-trims, :-trims]\n",
    "    n = corr.shape[0]\n",
    "    max_corr_ID = np.argmax(np.abs(corr) - np.eye(n))\n",
    "    return corr, np.unravel_index(max_corr_ID, [n,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the value, and row and column labels of a particular df coordinate. Rounding is arbitrary.\n",
    "def getCorrNameCoords(df, coordinates):\n",
    "    row = coordinates[0]; col = coordinates[1]\n",
    "    return round(df.iloc[row, col], 3), df.index[row], df.index[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_renames = {'ColdCode':'Cold',\n",
    "                  'FogCode':'Fog',\n",
    "                  'HailCode':'Hail',\n",
    "                  'SleetCode':'Sleet',\n",
    "                  'RainCode':'Rain',\n",
    "                  'SnowCode':'Snow',\n",
    "                  'HiWindCode':'Wind'}\n",
    "daily_weather.rename(columns=column_renames, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weather code correlation matrix:\n",
      "        Cold    Fog   Hail   Wind   Rain  Sleet   Snow\n",
      "Cold   1.000 -0.036 -0.007  0.006 -0.109  0.003 -0.002\n",
      "Fog   -0.036  1.000 -0.008 -0.011 -0.240  0.009  0.108\n",
      "Hail  -0.007 -0.008  1.000  0.016  0.049  0.026  0.015\n",
      "Wind   0.006 -0.011  0.016  1.000  0.047 -0.009  0.002\n",
      "Rain  -0.109 -0.240  0.049  0.047  1.000  0.001 -0.246\n",
      "Sleet  0.003  0.009  0.026 -0.009  0.001  1.000  0.210\n",
      "Snow  -0.002  0.108  0.015  0.002 -0.246  0.210  1.000\n",
      "Greatest correlation: (-0.246, 'Rain', 'Snow')\n"
     ]
    }
   ],
   "source": [
    "corr, coords_max_corr = corrMatrixAndMax(daily_weather, trims=1)\n",
    "print('\\nWeather code correlation matrix:\\n' + str(corr))\n",
    "print('Greatest correlation:', getCorrNameCoords(corr, coords_max_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rain and snow are negatively correlated, which makes sense, since snow requires below-\n",
    "freezing temperatures while rain rarely sees such temperatures. Close behind is the\n",
    "negative correlation between fog and rain, which is not too surprising either: Fog is a\n",
    "calm-weather event, and rain is often not. Note the positive correlation between sleet and\n",
    "snow, which we expect, but sleet and hail are almost completely uncorrelated despite once\n",
    "being the same code. The correlation between hail and high wind is surprisingly low, but\n",
    "high winds and hail do not require each other. That most of the correlations are low suggests\n",
    "that we can treat most of the variables separately when it is time to train the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total runtime: --- 69.29 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame and proceed to the flight_data.\n",
    "if save_data:\n",
    "    daily_weather.to_csv('daily_weather.csv')\n",
    "    corr.to_csv('weather_code_corr.csv')\n",
    "print('\\nTotal runtime:', stopwatch.getElapsedTime())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
